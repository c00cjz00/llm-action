

- 分散式訓練自動並行論文：https://zhuanlan.zhihu.com/p/642446009
- 北大河圖大模型自動並行訓練工具Galvatron：https://zhuanlan.zhihu.com/p/591924340
- 大規模模型訓練：https://www.zhihu.com/question/508671222
- 如何評價Google的GShard論文？：https://www.zhihu.com/question/404721763/answer/2111040851

---


大模型的自動並行之難主要體現在以下三個方面：

（1）多樣性：首先，在並行方式方面，目前大模型的並行方式呈現出百花齊放的態勢，
即使是對於同一個運算元，不考慮混合並行方式，不同的基礎並行方式也會存在顯著的差異，從而導致不同的記憶體開銷、通訊代價以及計算效率。
其次，在模型方面，各種各樣的模型架構最近也是層出不窮，這往往也伴隨著不同的模型配置（例如不同輸入序列長度，模型層數，模型隱層寬度等），從而造成計算負載上的差異。
另外，在硬體方面，使用者往往面臨著非常差異化的叢集環境，可能會面臨不同的記憶體容量、通訊頻寬、計算能力等等。
總體上來看，由於上述多樣性的存在，沒有哪種並行技術總是能夠獲得最佳訓練效率，“自動並行”也就成為了分散式訓練的核心挑戰。

（2）複雜性：上述分析還相對比較單一，實際上哪怕是對於同一個運算元也可以同時應用多種不同的基礎並行方式，
如果考慮到由這些基礎並行方式複合所構成的混合並行方式，則會導致問題變得非常複雜。
更重要的是，大模型的計算圖往往結構非常龐大，對應的也需要更大規模的叢集，如果對每個運算元都進行探索（包括選取叢集中合適的計算資源以及設計相應的混合並行方式），
會帶來組合空間爆炸的問題，尋找整個模型的最優分散式執行方案變得難以求解。


（3）實用性：除此之外，實用性也是非常重要的問題。
一方面，在進行自動並行搜尋的過程中，對於各種分散式執行方案，必須提供比較精確的記憶體、通訊、計算開銷，
否則會導致結果與實際執行偏差過大，產生次優解或者根本無法使用。
為此，就需要非常精準的代價模型，對不同的模型結構和硬體條件進行建模。
另一方面，系統提供自動並行能力所帶來的額外時間開銷必須在一個可以接受的範圍內，過於高昂的搜尋代價同樣也無法接受。






## One weird trick for parallelizing convolutional neural network
發現不同的層適合用不同的並行方式，具體的，卷積層資料比引數大，適合資料並行，全連線層引數比資料大，適合模型並行。

## Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks

Alex前面那篇文章直觀的提出來，有的層次適合資料並行，有的層次適合模型並行，那麼給定一個神經網路，有沒有自動的辦法找到最優的並行辦法呢？

這篇文章就是想解決這個問題。

首先，這篇文章在抽象上更進一步，發現數據並行，模型並行都只是張量切分方式的不同罷了，有的是切資料，有的是切模型，而且對於多維張量，在不同的維度上切分，效果也不同，譬如在sample, channel, width, length等維度都可以切分。

其次，不同的切分方式，都是一種構型（configuration)，不同的構型會導致不同的效果，所以尋找最優的並行方式，其實就是在構型空間裡面搜尋最優的構型而已，問題形式化成一個搜尋問題。

最後，引入了代價模型來衡量每個構型的優劣，並提出了一系列對搜尋空間剪枝的策略，並實現了原型系統。


這篇文章勾勒了自動並行的基本框架，很多解決自動並行的工作都是這樣一個流程。



## FlexFlow
Beyond Data and Model Parallelism for Deep Neural Networks


提出了execution simulator來完善cost model。



## Tofu

Tofu 提出了一套DSL，方便開發者描述張量的劃分策略，使用了類似poly的integer interval analysis來描述並行策略，同樣，並行策略的搜尋演算法上也做了很多很有特色的工作



Tofu與所有其它工作的不同之處在於，它的關注點是operator的劃分，其它工作的關注點是tensor的劃分，二者當然是等價的。不過，我認為關注點放在tensor的劃分上更好一些，這不需要使用者修改operator的實現，Tofu需要在DSL裡描述operator的實現方式。

這種區別也會反應到API層面，譬如Mindspore和OneFlow 作為通用框架裡少數實現了完整的資料並行、模型並行的系統，在Python API上也不同，在Mindspore訓練盤古模型的示例程式碼裡可以看到Mindspore 的劃分介面是放在operator上的，相反，OneFlow的SBP體系是把劃分介面放在張量上，在operator API上單卡和分散式完全一樣。





## Mesh-TensorFlow

Mesh-TensorFlow的核心理念也是beyond batch splitting，資料並行是batch splitting，模型並行是張量其它維度的切分。這篇文章把叢集的加速卡抽象成mesh結構，提出了一種把張量切分並對映到這個mesh結構的辦法。


## GShard




## GSPMD






# 全自動並行

## Alpa




## Unity











